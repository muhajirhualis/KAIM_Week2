{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b87f5e",
   "metadata": {},
   "source": [
    "## Task 2: Sentiment and Thematic Analysis\n",
    "This notebook serves as the execution and reporting layer for Task 2. All core logic—including sentiment scoring, TF-IDF, and rule-based thematic clustering—is executed via the modular Python scripts located in the src/ directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6222b174",
   "metadata": {},
   "source": [
    "### 1. Project Setup and Dependencies\n",
    "This section imports visualization tools and sets up the necessary file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e4bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08c249da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added project root to sys.path: d:\\DS_Courses\\KAIM_10_Academy\\KAIM_8\\Week_2\\KAIM_Week2\n"
     ]
    }
   ],
   "source": [
    "# Setup and Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Navigate up one level to the project root directory\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Add the project root to the Python system path list\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Added project root to sys.path: {project_root}\")\n",
    "\n",
    "# Set visualization styles\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abb70573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the custom class\n",
    "from src.preprocessor import ReviewPreprocessor\n",
    "from src.sentiment_analyzer import SentimentAnalyzer\n",
    "from src.thematic_analyzer import ThematicAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7290651e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 'reviews_processed.csv'\n"
     ]
    }
   ],
   "source": [
    "# ---  Data Loading ---\n",
    "try:\n",
    "    df = pd.read_csv('../data/processed/reviews_processed.csv')\n",
    "    print(\"Successfully loaded 'reviews_processed.csv'\")\n",
    "except FileNotFoundError:\n",
    "    print(\"WARNING: Data file not found. Please ensure data is in '../data/processed/'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a8e4e3",
   "metadata": {},
   "source": [
    "### 2. Analysis Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac5b96",
   "metadata": {},
   "source": [
    "2.1 Sentiment Analysis Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9977c648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\MUHAJER HUALIS\\AppData\\Local\\Temp\\ipykernel_17544\\4268104097.py:6: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  print(\"\\Textblob Analysis Results Sample:\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sentiment analysis using TextBlob...\n",
      "TextBlob analysis complete.\n",
      "\\Textblob Analysis Results Sample:\n",
      "                                         review_text  rating  tb_polarity  \\\n",
      "0                   bad exprience...it is so crushed       1    -0.400000   \n",
      "1  not user friendly at all it requires a huge co...       1     0.425000   \n",
      "2           most of the time is not working properly       1     0.250000   \n",
      "3  It keeps notifying me to disable developer opt...       1     0.068182   \n",
      "4  the lag is unbelievable when you need it the m...       1     0.125000   \n",
      "\n",
      "   tb_subjectivity  \n",
      "0         0.383333  \n",
      "1         0.633333  \n",
      "2         0.300000  \n",
      "3         0.393939  \n",
      "4         0.750000  \n"
     ]
    }
   ],
   "source": [
    "# --- Sentiment Analysis  ---\n",
    "sentiment_processor = SentimentAnalyzer(df=df.copy())\n",
    "df_with_sentiment = sentiment_processor.analyze_textblob()\n",
    "\n",
    "# Show output (Verification step for the report)\n",
    "print(\"\\Textblob Analysis Results Sample:\")\n",
    "print(\n",
    "    df_with_sentiment[[\n",
    "        \"review_text\", \"rating\", \"tb_polarity\", \"tb_subjectivity\"\n",
    "    ]].head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "697816d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sentiment analysis using VADER...\n",
      "VADER analysis complete.\n",
      "\n",
      "VADER Analysis Results Sample:\n",
      "                                         review_text  rating  vader_compound  \\\n",
      "0                   bad exprience...it is so crushed       1         -0.7973   \n",
      "1  not user friendly at all it requires a huge co...       1         -0.4268   \n",
      "2           most of the time is not working properly       1          0.0000   \n",
      "3  It keeps notifying me to disable developer opt...       1         -0.4019   \n",
      "4  the lag is unbelievable when you need it the m...       1         -0.1531   \n",
      "\n",
      "  vader_sentiment  \n",
      "0        Negative  \n",
      "1        Negative  \n",
      "2         Neutral  \n",
      "3        Negative  \n",
      "4        Negative  \n"
     ]
    }
   ],
   "source": [
    "# --- VADER Sentiment Analysis  ---\n",
    "\n",
    "# Re-initialize or continue with the same processor instance if you want to run both:\n",
    "if 'df_with_sentiment' not in locals():\n",
    "    df_with_sentiment = df.copy()\n",
    "\n",
    "sentiment_processor = SentimentAnalyzer(df=df_with_sentiment)\n",
    "df_with_all_sentiment = sentiment_processor.analyze_vader()\n",
    "\n",
    "# Show output (Verification step for the report)\n",
    "print(\"\\nVADER Analysis Results Sample:\")\n",
    "print(\n",
    "    df_with_all_sentiment[[\n",
    "        \"review_text\", \"rating\", \"vader_compound\", \"vader_sentiment\"\n",
    "    ]].head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ed8a1b",
   "metadata": {},
   "source": [
    "2.2 Thematic Analysis and Grouping Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6ed8a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text for TF-IDF...\n",
      "TF-IDF analysis complete. Found 469 features.\n",
      "\n",
      "Cleaned Reviews Sample (Thematic Preprocessing):\n",
      "                                         review_text  \\\n",
      "0                   bad exprience...it is so crushed   \n",
      "1  not user friendly at all it requires a huge co...   \n",
      "2           most of the time is not working properly   \n",
      "3  It keeps notifying me to disable developer opt...   \n",
      "4  the lag is unbelievable when you need it the m...   \n",
      "\n",
      "                                      cleaned_review  \n",
      "0                     bad exprience it is so crushed  \n",
      "1  not user friendly at all it requires a huge co...  \n",
      "2           most of the time is not working properly  \n",
      "3  it keeps notifying me to disable developer opt...  \n",
      "4  the lag is unbelievable when you need it the m...  \n"
     ]
    }
   ],
   "source": [
    "# --- Thematic Analysis (Keyword Extraction) ---\n",
    "\n",
    "# 'df_with_sentiment' contains the data from the previous step.\n",
    "thematic_processor = ThematicAnalyzer(df=df_with_sentiment.copy())\n",
    "\n",
    "# This single call runs the preprocessing AND the TF-IDF vectorization\n",
    "thematic_processor.extract_keywords_tfidf() \n",
    "\n",
    "\n",
    "# Verification: Show the new column\n",
    "print(\"\\nCleaned Reviews Sample (Thematic Preprocessing):\")\n",
    "print(thematic_processor.df[['review_text', 'cleaned_review']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78f43c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text for TF-IDF...\n",
      "TF-IDF analysis complete. Found 469 features.\n",
      "\n",
      "Top 10 Most Significant Keywords (Mean TF-IDF Score):\n",
      "          word     tfidf\n",
      "0          app  0.098637\n",
      "1         good  0.054004\n",
      "2         best  0.038600\n",
      "3         bank  0.037071\n",
      "4          use  0.027366\n",
      "5      banking  0.026982\n",
      "6     good app  0.025107\n",
      "7         easy  0.023530\n",
      "8  application  0.022963\n",
      "9       dashen  0.021473\n"
     ]
    }
   ],
   "source": [
    "# --- Thematic Analysis: Keyword Extraction ---\n",
    "\n",
    "# Assuming 'df_with_sentiment' contains the data from the sentiment step.\n",
    "\n",
    "thematic_processor = ThematicAnalyzer(df=df_with_sentiment.copy())\n",
    "\n",
    "# This single call runs cleaning, vectorization, and mean calculation\n",
    "keywords_df = thematic_processor.extract_keywords_tfidf() \n",
    "\n",
    "# Show output (Verification and reporting step)\n",
    "print(\"\\nTop 10 Most Significant Keywords (Mean TF-IDF Score):\")\n",
    "print(keywords_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4443897",
   "metadata": {},
   "source": [
    "Topic Modeling (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38dfd891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting LDA Topic Modeling (4 Topics) ---\n",
      "LDA modeling complete.\n",
      "--- Topic 1 ---\n",
      "good             weight=0.0740\n",
      "use              weight=0.0497\n",
      "easy             weight=0.0471\n",
      "bank             weight=0.0467\n",
      "dashen           weight=0.0297\n",
      "work             weight=0.0272\n",
      "super            weight=0.0213\n",
      "fast             weight=0.0208\n",
      "great            weight=0.0177\n",
      "please           weight=0.0171\n",
      "\n",
      "--- Topic 2 ---\n",
      "bank             weight=0.0352\n",
      "banking          weight=0.0328\n",
      "one              weight=0.0272\n",
      "dashen           weight=0.0271\n",
      "user             weight=0.0237\n",
      "super            weight=0.0222\n",
      "ever             weight=0.0200\n",
      "experience       weight=0.0191\n",
      "amazing          weight=0.0170\n",
      "friendly         weight=0.0164\n",
      "\n",
      "--- Topic 3 ---\n",
      "banking          weight=0.0376\n",
      "best             weight=0.0376\n",
      "mobile           weight=0.0329\n",
      "money            weight=0.0252\n",
      "time             weight=0.0219\n",
      "bank             weight=0.0199\n",
      "nice             weight=0.0165\n",
      "even             weight=0.0164\n",
      "one              weight=0.0156\n",
      "application      weight=0.0146\n",
      "\n",
      "--- Topic 4 ---\n",
      "working          weight=0.0336\n",
      "developer        weight=0.0285\n",
      "please           weight=0.0258\n",
      "phone            weight=0.0209\n",
      "open             weight=0.0199\n",
      "fix              weight=0.0184\n",
      "apps             weight=0.0178\n",
      "update           weight=0.0164\n",
      "need             weight=0.0153\n",
      "transaction      weight=0.0152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Advanced Thematic Analysis: LDA Topic Modeling ---\n",
    "# This is used for discovering themes, informing the rule-based clustering.\n",
    "\n",
    "# Assuming 'df_with_sentiment' contains the data from the previous step.\n",
    "thematic_processor = ThematicAnalyzer(df=df_with_sentiment.copy())\n",
    "\n",
    "# Run the full LDA pipeline via the modular method\n",
    "lda_results = thematic_processor.run_lda_topic_modeling(num_topics=4)\n",
    "\n",
    "# Display the output (Reporting step)\n",
    "print(lda_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05b81ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Bank of Abyssinia (370 reviews) ===\n",
      "Topic 1: app, best, easy, fast, worest, worest app, best app, disappointing\n",
      "Topic 2: app, worst, banking, mobile, working, worst app, doesn, work\n",
      "Topic 3: good, works, update, better, app, really, needs, work\n",
      "Topic 4: bank, good, app, bad, slow, good app, application, good application\n",
      "\n",
      "=== Commercial Bank of Ethiopia (303 reviews) ===\n",
      "Topic 1: app, bank, good app, banking, good, transaction, history, mobile\n",
      "Topic 2: best, good, application, app, fast, service, useful, add\n",
      "Topic 3: app, use, easy, easy use, nice, life, money, problem\n",
      "Topic 4: cbe, excellent, time, user, works, application, work, friendly\n",
      "\n",
      "=== Dashen Bank (424 reviews) ===\n",
      "Topic 1: use, easy, app, slow, easy use, application, transaction, dashen\n",
      "Topic 2: bank, app, good, working, account, nice, option, app good\n",
      "Topic 3: app, best, dashen, user, super, fast, banking, good\n",
      "Topic 4: mobile, star, mobile banking, banking, worst, worst app, app, takes\n"
     ]
    }
   ],
   "source": [
    "# --- Bank-Specific Thematic Analysis (LDA) ---\n",
    "\n",
    "# Assuming 'df_with_sentiment' contains the final data.\n",
    "thematic_processor = ThematicAnalyzer(df=df_with_sentiment.copy())\n",
    "\n",
    "# Run the bank-specific LDA pipeline via the modular method\n",
    "bank_lda_results = thematic_processor.run_lda_by_bank(n_topics=4)\n",
    "\n",
    "# Display the output (Reporting step)\n",
    "print(bank_lda_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72ac41b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rule-based thematic clustering...\n",
      "Thematic assignment complete.\n",
      "\n",
      "Rule-Based Theme Assignment Sample:\n",
      "                                      cleaned_review  \\\n",
      "0                     bad exprience it is so crushed   \n",
      "1  not user friendly at all it requires a huge co...   \n",
      "2           most of the time is not working properly   \n",
      "3  it keeps notifying me to disable developer opt...   \n",
      "4  the lag is unbelievable when you need it the m...   \n",
      "\n",
      "                         theme  \n",
      "0                        other  \n",
      "1  User Experience (UI/Design)  \n",
      "2                        other  \n",
      "3         App Stability & Bugs  \n",
      "4                        other  \n"
     ]
    }
   ],
   "source": [
    "# --- Rule-Based Theme Assignment ---\n",
    "# Replaces the THEME_MAPPING definition and the df.apply logic\n",
    "\n",
    "# The ThematicAnalyzer instance already holds the df (df_with_sentiment).\n",
    "df_final_analyzed = thematic_processor.assign_themes(top_k=1)\n",
    "\n",
    "# Verification: Show the new 'theme' column\n",
    "print(\"\\nRule-Based Theme Assignment Sample:\")\n",
    "print(df_final_analyzed[['cleaned_review', 'theme']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbc4d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1195 analyzed records for visualization.\n",
      "\n",
      "--- Thematic Sentiment Summary ---\n",
      "                        mean  count\n",
      "theme                              \n",
      "user-sentiment     -0.417632     76\n",
      "performance        -0.054321     76\n",
      "core-functionality  0.139479    106\n",
      "other               0.281353    768\n",
      "feature-requests    0.351479     28\n",
      "ui-ux               0.656111    141\n"
     ]
    }
   ],
   "source": [
    "# --- Data Loading for Reporting ---\n",
    "import pandas as pd\n",
    "from config import DATA_PATHS\n",
    "\n",
    "# Load the final file created by the pipeline.py script\n",
    "REPORTING_FILE = DATA_PATHS['final_results']\n",
    "df_final = pd.read_csv(REPORTING_FILE)\n",
    "\n",
    "print(f\"Loaded {len(df_final)} analyzed records for visualization.\")\n",
    "\n",
    "# --- Visualization 1: Theme Sentiment Aggregation ---\n",
    "theme_sentiment = (\n",
    "    df_final.groupby('theme')['sentiment_score']\n",
    "    .agg(['mean', 'count'])\n",
    "    .sort_values('mean')\n",
    ")\n",
    "\n",
    "print(\"\\n--- Thematic Sentiment Summary ---\")\n",
    "print(theme_sentiment)\n",
    "\n",
    "# --- Visualization 2: Plotting Code ---\n",
    "# Use df_final for all subsequent plotting and aggregation code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
